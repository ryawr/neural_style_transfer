{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_style_transfer",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLw_abX6WsW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "from nst_utils import *\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pprint\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le97jbXqPc5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n",
        "pp.pprint(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsrTHrriQFzX",
        "colab_type": "text"
      },
      "source": [
        "Content cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHSaGKbwPlf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_content_cost(a_C, a_G):\n",
        "    \"\"\"    \n",
        "    Arguments:\n",
        "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
        "    \n",
        "    \"\"\"\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    a_C_unrolled = tf.reshape(a_C, shape=[m, n_H*n_W, n_C])\n",
        "    a_G_unrolled = tf.reshape(a_G, [m, n_H*n_W, n_C])\n",
        "    \n",
        "    # content cost\n",
        "    J_content = tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled)))/(4*n_H*n_W*n_C)\n",
        "    \n",
        "    return J_content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfYuGo9mQq5-",
        "colab_type": "text"
      },
      "source": [
        "Layer style cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r8rlN7mQJWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_layer_style_cost(a_S, a_G):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    a_S = tf.reshape(tf.transpose(a_S, perm = [0,3,1,2]), shape=[m,n_C,n_H*n_W])\n",
        "    a_G = tf.reshape(tf.transpose(a_G, perm = [0,3,1,2]), shape=[m,n_C,n_H*n_W])\n",
        "\n",
        "    GS = tf.matmul(a_S, tf.transpose(a_S, perm = [0,2,1]))\n",
        "    GG = tf.matmul(a_G, tf.transpose(a_G, perm = [0,2,1]))\n",
        "\n",
        "    # layer style cost\n",
        "    J_style_layer = tf.reduce_sum(tf.square(tf.subtract(GS, GG)))/((2*n_C*n_H*n_W)*(2*n_C*n_H*n_W))\n",
        "    \n",
        "    return J_style_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_5smrQaQuKQ",
        "colab_type": "text"
      },
      "source": [
        "Overall style cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ocEHCyTQ9SM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# style contribution weightage for every layer\n",
        "\n",
        "STYLE_LAYERS = [\n",
        "    ('conv1_1', 0.2),\n",
        "    ('conv2_1', 0.2),\n",
        "    ('conv3_1', 0.2),\n",
        "    ('conv4_1', 0.2),\n",
        "    ('conv5_1', 0.2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz0I3Ax0ROc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_style_cost(model, STYLE_LAYERS):\n",
        "    \n",
        "    J_style = 0\n",
        "\n",
        "    for layer_name, coeff in STYLE_LAYERS:\n",
        "\n",
        "        out = model[layer_name]\n",
        "        a_S = sess.run(out)\n",
        "        \n",
        "        # a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n",
        "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "        a_G = out\n",
        "        \n",
        "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
        "        J_style += coeff * J_style_layer\n",
        "\n",
        "    return J_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crkAfU5eSh_2",
        "colab_type": "text"
      },
      "source": [
        "Total cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9yE_u4NSYnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
        "    \n",
        "    J = alpha*J_content + beta*J_style\n",
        "    \n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bF87OYsX3MG",
        "colab_type": "text"
      },
      "source": [
        "Optimization\n",
        "\n",
        "(after reading the content and style image, and generating the noise image(input image) to start with)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq6sCP7sSlCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assigning the input of the model to be the \"content\" image\n",
        "sess.run(model['input'].assign(content_image))\n",
        "\n",
        "out = model['conv4_2']\n",
        "a_C = sess.run(out)\n",
        "a_G = out\n",
        "\n",
        "# content cost\n",
        "J_content = compute_content_cost(a_C, a_G)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP59uUOITlZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assigning the input of the model to be the \"style\" image \n",
        "sess.run(model['input'].assign(style_image))\n",
        "\n",
        "J_style = compute_style_cost(model, STYLE_LAYERS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYuHjmFYTzS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "J = 10*J_content + 40*J_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1UIyEXXT3-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining optimizer\n",
        "optimizer = tf.train.AdamOptimizer(2.0)\n",
        "train_step = optimizer.minimize(J)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh9ua2IlUNu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_nn(sess, input_image, num_iterations = 200):\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    model[\"input\"].assign(input_image)\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "    \n",
        "        sess.run(train_step)\n",
        "        \n",
        "        # Computing the generated image by running the session on the current model['input']\n",
        "        generated_image = sess.run(model[\"input\"])\n",
        "\n",
        "        # Print every 20 iteration.\n",
        "        if i%20 == 0:\n",
        "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
        "            print(\"Iteration \" + str(i) + \" :\")\n",
        "            print(\"total cost = \" + str(Jt))\n",
        "            print(\"content cost = \" + str(Jc))\n",
        "            print(\"style cost = \" + str(Js))\n",
        "            \n",
        "            save_image(\"output/\" + str(i) + \".png\", generated_image)\n",
        "    \n",
        "    # saving last generated image\n",
        "    save_image('output/generated_image.jpg', generated_image)\n",
        "    \n",
        "    return generated_image"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}